# Automating-AI-with-Code
# å®‰è£ Gemini å¥—ä»¶ï¼ˆåªéœ€ç¬¬ä¸€æ¬¡åŸ·è¡Œï¼‰
!pip install -q -U google-generativeai

# åŒ¯å…¥å‡½å¼åº«
import google.generativeai as genai
from google.colab import userdata
import os
import time

# è®€å–é‡‘é‘°
api_key = userdata.get('GEMINI_API_KEY')

if not api_key:
    print("âŒ ç„¡æ³•è®€å– GEMINI_API_KEYï¼Œè«‹å…ˆåœ¨å·¦é‚Š ğŸ”‘ è¼¸å…¥ä½ çš„ API é‡‘é‘°")
else:
    print(f"ğŸ”‘ å·²è®€å–é‡‘é‘°ï¼ˆéƒ¨åˆ†é®è”½ï¼‰ï¼š{api_key[:4]}...{api_key[-4:]}")
    genai.configure(api_key=api_key)

    # âš™ï¸ è¨­å®šæ¨¡å‹ï¼ˆå¯æ”¹ç‚º gemini-1.5-proï¼‰
    MODEL_NAME = "models/gemini-1.5-flash"

    # âœ… æ§åˆ¶æ˜¯å¦çœŸçš„è¦ç™¼é€ prompt
    run_prompt = True

    # âœ… ä½ è¦å•çš„å•é¡Œ
    prompt = "è«‹å¹«æˆ‘å¯«ä¸€æ®µ Python æœ€å¥½çš„å…¥é–€æ–¹æ³•"

    # âœ… å›æ‡‰å¿«å–æª”å
    CACHE_FILE = "gemini_response.txt"

    if os.path.exists(CACHE_FILE):
        print(f"ğŸ“„ å·²æœ‰å¿«å–ï¼Œä»¥ä¸‹æ˜¯ä¹‹å‰çš„å›è¦†ï¼š\n")
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            print(f.read())
    elif run_prompt:
        try:
            model = genai.GenerativeModel(model_name=MODEL_NAME)
            print("ğŸ§  æ­£åœ¨å‘¼å« Gemini API...")
            time.sleep(2)  # é¿å…429éŒ¯èª¤

            response = model.generate_content(prompt)
            answer = response.text

            print("âœ… Gemini å›è¦†ï¼š\n", answer)

            with open(CACHE_FILE, "w", encoding="utf-8") as f:
                f.write(answer)
        except Exception as e:
            print("âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š", e)
    else:
        print("ğŸ›‘ æ¸¬è©¦æ¨¡å¼ä¸­ï¼Œæœªç™¼é€ API è«‹æ±‚ã€‚è«‹å°‡ run_prompt æ”¹ç‚º Trueã€‚")
